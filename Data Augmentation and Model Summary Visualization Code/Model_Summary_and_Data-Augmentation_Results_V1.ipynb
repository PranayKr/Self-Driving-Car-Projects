{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Lambda, Cropping2D, Convolution2D, ELU, Flatten, Dense, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from random import shuffle\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Visualizations will be shown in the notebook.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (160, 320, 3)\n",
    "LEARNING_PARAMETER = .0001 #1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (5, 5), activation=\"elu\", strides=(2, 2), padding=\"same\")`\n",
      "  after removing the cwd from sys.path.\n",
      "E:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(36, (5, 5), activation=\"elu\", strides=(2, 2), padding=\"same\")`\n",
      "  \"\"\"\n",
      "E:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (5, 5), activation=\"elu\", strides=(2, 2), padding=\"valid\")`\n",
      "  \n",
      "E:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"elu\", padding=\"valid\")`\n",
      "  import sys\n",
      "E:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"elu\", padding=\"valid\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x/255.-0.5,input_shape=INPUT_SHAPE))\n",
    "model.add(Cropping2D(cropping=((70, 25), (0, 0))))\n",
    "model.add(Convolution2D(24, 5, 5, border_mode=\"same\", subsample=(2,2), activation=\"elu\"))\n",
    "model.add(Convolution2D(36, 5, 5, border_mode=\"same\", subsample=(2,2), activation=\"elu\"))\n",
    "model.add(Convolution2D(48, 5, 5, border_mode=\"valid\", subsample=(2,2), activation=\"elu\"))\n",
    "model.add(Convolution2D(64, 3, 3, border_mode=\"valid\", activation=\"elu\"))\n",
    "model.add(Convolution2D(64, 3, 3, border_mode=\"valid\", activation=\"elu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, activation=\"elu\"))\n",
    "model.add(Dense(50, activation=\"elu\"))\n",
    "model.add(Dense(10, activation=\"elu\"))\n",
    "model.add(Dense(1))\n",
    "\n",
    "adam = Adam(lr=LEARNING_PARAMETER)\n",
    "model.compile(optimizer=adam,loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_1 (Lambda)            (None, 160, 320, 3)       0         \n",
      "_________________________________________________________________\n",
      "cropping2d_1 (Cropping2D)    (None, 65, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 33, 160, 24)       1824      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 17, 80, 36)        21636     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 38, 48)         43248     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 5, 36, 64)         27712     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 34, 64)         36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6528)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6528)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               652900    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 789,819\n",
      "Trainable params: 789,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_IMG = 'C:/Users/Dell/Desktop/Behavior-Cloning/sim_data/sim_data/data/IMG/'\n",
    "PATH_TO_CSV = 'C:/Users/Dell/Desktop/Behavior-Cloning/sim_data/sim_data/data/driving_log.csv'\n",
    "CORRECTION = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv():\n",
    "    df = pd.read_csv(PATH_TO_CSV, index_col=False)\n",
    "    df.columns = ['center', 'left', 'right', 'steer', 'throttle', 'brake', 'speed']\n",
    "    df = df.sample(n=len(df))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly selecting the let, right, and center images\n",
    "def random_select_image(data, i , default=0):\n",
    "     \n",
    "    random = np.random.randint(3)\n",
    "    \n",
    "    path = \" \"\n",
    "    \n",
    "    if random == 0:\n",
    "        path = PATH_TO_IMG+data['left'][i].split('/')[-1]\n",
    "        \n",
    "        difference = CORRECTION\n",
    "    elif random == 1:\n",
    "        path = PATH_TO_IMG+data['center'][i].split('/')[-1]\n",
    "        \n",
    "        difference = 0 \n",
    "    elif random == 2:\n",
    "        path = PATH_TO_IMG+data['right'][i].split('/')[-1]\n",
    "       \n",
    "        difference = -CORRECTION\n",
    "        \n",
    "    image = cv2.imread(path)\n",
    "    \n",
    "    #image = cv2.resize(image, (160, 320), cv2.INTER_AREA)\n",
    "    \n",
    "    image_converted = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    angle = float(data['steer'][i])+difference\n",
    "    \n",
    "    f, (ax1,ax2) = plt.subplots(1, 2, figsize=(11,11))\n",
    "    \n",
    "    if(difference==0):\n",
    "        ax1.set_title('Center Image in BGR Color Space')\n",
    "    elif(difference>0):\n",
    "        ax1.set_title('Left Image in BGR Color Space')\n",
    "    elif(difference<0):\n",
    "        ax1.set_title('Right Image in BGR Color Space')\n",
    "    ax1.imshow(image)\n",
    "    ax1.set_xlabel(\"Steering Angle:\"+ str(float(data['steer'][i])))\n",
    "    if(difference==0):\n",
    "        ax2.set_title('Center Image in RGB Color Space')\n",
    "    elif(difference>0):\n",
    "        ax2.set_title('Left Image in RGB Color Space')\n",
    "    elif(difference<0):\n",
    "        ax2.set_title('Right Image in RGB Color Space')\n",
    "    ax2.imshow(image_converted)\n",
    "    if(difference==0):\n",
    "        ax2.set_xlabel(\"Steering Angle (No Correction):\"+ str(angle))\n",
    "    elif(difference>0 or difference<0):\n",
    "        ax2.set_xlabel(\"Original Steering Angle:\"+str(float(data['steer'][i]))+\"\\n Steering Angle with Correction:\"+ str(angle))\n",
    "    \n",
    "    \n",
    "  \n",
    "    return image_converted, angle , difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_img_angle(image, angle , difference):\n",
    "    image_flipped = cv2.flip(image, 1)\n",
    "    flppedangle = -1.0 * angle\n",
    "    \n",
    "    f, (ax1,ax2) = plt.subplots(1, 2, figsize=(11,11))\n",
    "    \n",
    "    if(difference==0):\n",
    "        ax1.set_title('Unflipped Center Image in RGB Color Space')\n",
    "    elif(difference>0):\n",
    "        ax1.set_title('Unflipped Left Image in RGB Color Space')\n",
    "    elif(difference<0):\n",
    "        ax1.set_title('Unflipped Right Image in RGB Color Space')\n",
    "    ax1.imshow(image)\n",
    "    ax1.set_xlabel(\"Steering Angle:\"+ str(angle))\n",
    "    if(difference==0):\n",
    "        ax2.set_title('Flipped Center Image in RGB Color Space')\n",
    "    elif(difference>0):\n",
    "        ax2.set_title('Flipped Left Image in RGB Color Space')\n",
    "    elif(difference<0):\n",
    "        ax2.set_title('Flipped Right Image in RGB Color Space')\n",
    "    ax2.imshow(image_flipped)\n",
    "    ax2.set_xlabel(\"Flipped Steering Angle:\"+ str(flppedangle))\n",
    "    \n",
    "\n",
    "    return image_flipped, angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brightnessed_img(origimage,difference):\n",
    "    image = cv2.cvtColor(origimage, cv2.COLOR_RGB2HSV)\n",
    "    #image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    random_bright = .25 + np.random.uniform()\n",
    "    image[:,:,2] = image[:,:,2] * random_bright\n",
    "    image_brightalter = cv2.cvtColor(image, cv2.COLOR_HSV2RGB)\n",
    "    #image = cv2.cvtColor(image, cv2.COLOR_HSV2BGR)\n",
    "    f, (ax1,ax2) = plt.subplots(1, 2, figsize=(11,11))\n",
    "    \n",
    "    if(difference==0):\n",
    "        ax1.set_title('Original Center Image in RGB Color Space')\n",
    "    elif(difference>0):\n",
    "        ax1.set_title('Original Left Image in RGB Color Space')\n",
    "    elif(difference<0):\n",
    "        ax1.set_title('Original Right Image in RGB Color Space')\n",
    "    ax1.imshow(origimage)\n",
    "    #ax1.set_xlabel(\"Steering Angle:\"+ str(angle))\n",
    "    if(difference==0):\n",
    "        ax2.set_title('Brightness-Altered Center Image in RGB Color Space')\n",
    "    elif(difference>0):\n",
    "        ax2.set_title('Brightness-Altered Left Image in RGB Color Space')\n",
    "    elif(difference<0):\n",
    "        ax2.set_title('Brightness-Altered Right Image in RGB Color Space')\n",
    "    ax2.imshow(image_brightalter)\n",
    "    \n",
    "    #ax2.set_xlabel(\"Flipped Steering Angle:\"+ str(flppedangle))\"\"\"\n",
    "    \n",
    "    return image_brightalter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_image(image, steer , difference):\n",
    "    trans_range = 100\n",
    "    tr_x = trans_range * np.random.uniform() - trans_range / 2\n",
    "    steer_ang = steer + tr_x / trans_range * 2 * .2\n",
    "    tr_y = 0\n",
    "    M = np.float32([[1, 0, tr_x], [0, 1, tr_y]])\n",
    "    image_tr = cv2.warpAffine(image, M, (INPUT_SHAPE[1], INPUT_SHAPE[0]))\n",
    "    \n",
    "    \"\"\"f, (ax1,ax2) = plt.subplots(1, 2, figsize=(11,11))\n",
    "    \n",
    "    if(difference==0):\n",
    "        ax1.set_title('Original Center Image in RGB Color Space')\n",
    "    elif(difference>0):\n",
    "        ax1.set_title('Original Left Image in RGB Color Space')\n",
    "    elif(difference<0):\n",
    "        ax1.set_title('Original Right Image in RGB Color Space')\n",
    "    ax1.imshow(image)\n",
    "    ax1.set_xlabel(\"Steering Angle:\"+ str(steer))\n",
    "    if(difference==0):\n",
    "        ax2.set_title('Translated Center Image in RGB Color Space')\n",
    "    elif(difference>0):\n",
    "        ax2.set_title('Translated Left Image in RGB Color Space')\n",
    "    elif(difference<0):\n",
    "        ax2.set_title('Translated Right Image in RGB Color Space')\n",
    "    ax2.imshow(image_tr)\n",
    "    ax2.set_xlabel(\"Steering Angle after translation:\"+ str(steer_ang))\"\"\"\n",
    "    \n",
    "    return image_tr, steer_ang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting fetatures and lables from training and validation data\n",
    "def get_data(data):\n",
    "    images = []\n",
    "    angles = []\n",
    "    for i in data.index:\n",
    "        image, angle , difference = random_select_image(data, i , 0)\n",
    "\n",
    "        # Data augumentation\n",
    "        if np.random.uniform() < 0.5:\n",
    "            image, angle = flip_img_angle(image, angle , difference)\n",
    "        image = brightnessed_img(image,difference)\n",
    "        image, angle = trans_image(image, angle,difference)\n",
    "        images.append(image)\n",
    "        angles.append(angle)\n",
    "\n",
    "    # Creating as numpy array\n",
    "    X = np.array(images)\n",
    "    y = np.array(angles)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = get_csv()\n",
    "\n",
    "# Training and Validation data\n",
    "training_count = int(0.8 * len(samples))\n",
    "training_data = samples[:training_count].reset_index()\n",
    "validation_data = samples[training_count:].reset_index()\n",
    "\n",
    "# Getting features and labels for training and validation.\n",
    "X_train, y_train = get_data(training_data)\n",
    "X_valid, y_valid = get_data(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
